{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FaishalRayyan_RegresiProject.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zq6lELn4R96g"
      },
      "source": [
        "Prediksi umur abalone menggunakan kondisi pengukuran fisik. Umur abalone ditentukan dengan memotong cangkangnya, menodai, dan menghitung jumlah 'ring' melalui mikroskop.\n",
        "\n",
        "\n",
        "*   Sex \t\t\t: Male, Female, and I (infant)\n",
        "*   Length \t\t: Panjang cangkang dalam milimeter\n",
        "*   Diameter \t\t: Diameter dalam milimeter\n",
        "*   Height \t\t\t: Tinggi termasuk daging dalam cangkang dalam milimeter\n",
        "*   Whole weight \t\t: Berat keseluruhan abalone dalam gram\n",
        "*   Shucked weight\t: Berat daging abalone gram\n",
        "*   Viscera weight \t: Berat usus abalone setelah dikeringkan gram\n",
        "*   Shell weight \t\t: Berat cangkang setelah dikeringkan gram\n",
        "*   Rings \t\t\t: Jumlah rings yang jika ditambahkan 1.5 akan menunjukkan umur abalon "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "m1OsSuz1Q8ZK",
        "outputId": "d3eb61e2-9f7c-46ac-bc78-c0b9e9c1edf0"
      },
      "source": [
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6976fdc6-3098-4b34-90c6-b6ab9ff0b26d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6976fdc6-3098-4b34-90c6-b6ab9ff0b26d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Abalone.csv to Abalone (1).csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XH0XItyQ8yR"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "c1Wb2TTORMer",
        "outputId": "c061fdf3-ed57-4987-d57c-47f039fa7e74"
      },
      "source": [
        "df = pd.read_csv(io.BytesIO(uploaded[\"Abalone.csv\"]))\n",
        "df"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sex</th>\n",
              "      <th>Length</th>\n",
              "      <th>Diameter</th>\n",
              "      <th>Height</th>\n",
              "      <th>Whole weight</th>\n",
              "      <th>Shucked weight</th>\n",
              "      <th>Viscera weight</th>\n",
              "      <th>Shell weight</th>\n",
              "      <th>Rings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>M</td>\n",
              "      <td>0.455</td>\n",
              "      <td>0.365</td>\n",
              "      <td>0.095</td>\n",
              "      <td>0.5140</td>\n",
              "      <td>0.2245</td>\n",
              "      <td>0.1010</td>\n",
              "      <td>0.1500</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>M</td>\n",
              "      <td>0.350</td>\n",
              "      <td>0.265</td>\n",
              "      <td>0.090</td>\n",
              "      <td>0.2255</td>\n",
              "      <td>0.0995</td>\n",
              "      <td>0.0485</td>\n",
              "      <td>0.0700</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>F</td>\n",
              "      <td>0.530</td>\n",
              "      <td>0.420</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.6770</td>\n",
              "      <td>0.2565</td>\n",
              "      <td>0.1415</td>\n",
              "      <td>0.2100</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>M</td>\n",
              "      <td>0.440</td>\n",
              "      <td>0.365</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.5160</td>\n",
              "      <td>0.2155</td>\n",
              "      <td>0.1140</td>\n",
              "      <td>0.1550</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I</td>\n",
              "      <td>0.330</td>\n",
              "      <td>0.255</td>\n",
              "      <td>0.080</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.0895</td>\n",
              "      <td>0.0395</td>\n",
              "      <td>0.0550</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4172</th>\n",
              "      <td>F</td>\n",
              "      <td>0.565</td>\n",
              "      <td>0.450</td>\n",
              "      <td>0.165</td>\n",
              "      <td>0.8870</td>\n",
              "      <td>0.3700</td>\n",
              "      <td>0.2390</td>\n",
              "      <td>0.2490</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4173</th>\n",
              "      <td>M</td>\n",
              "      <td>0.590</td>\n",
              "      <td>0.440</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.9660</td>\n",
              "      <td>0.4390</td>\n",
              "      <td>0.2145</td>\n",
              "      <td>0.2605</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4174</th>\n",
              "      <td>M</td>\n",
              "      <td>0.600</td>\n",
              "      <td>0.475</td>\n",
              "      <td>0.205</td>\n",
              "      <td>1.1760</td>\n",
              "      <td>0.5255</td>\n",
              "      <td>0.2875</td>\n",
              "      <td>0.3080</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4175</th>\n",
              "      <td>F</td>\n",
              "      <td>0.625</td>\n",
              "      <td>0.485</td>\n",
              "      <td>0.150</td>\n",
              "      <td>1.0945</td>\n",
              "      <td>0.5310</td>\n",
              "      <td>0.2610</td>\n",
              "      <td>0.2960</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4176</th>\n",
              "      <td>M</td>\n",
              "      <td>0.710</td>\n",
              "      <td>0.555</td>\n",
              "      <td>0.195</td>\n",
              "      <td>1.9485</td>\n",
              "      <td>0.9455</td>\n",
              "      <td>0.3765</td>\n",
              "      <td>0.4950</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4177 rows Ã— 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Sex  Length  Diameter  ...  Viscera weight  Shell weight  Rings\n",
              "0      M   0.455     0.365  ...          0.1010        0.1500     15\n",
              "1      M   0.350     0.265  ...          0.0485        0.0700      7\n",
              "2      F   0.530     0.420  ...          0.1415        0.2100      9\n",
              "3      M   0.440     0.365  ...          0.1140        0.1550     10\n",
              "4      I   0.330     0.255  ...          0.0395        0.0550      7\n",
              "...   ..     ...       ...  ...             ...           ...    ...\n",
              "4172   F   0.565     0.450  ...          0.2390        0.2490     11\n",
              "4173   M   0.590     0.440  ...          0.2145        0.2605     10\n",
              "4174   M   0.600     0.475  ...          0.2875        0.3080      9\n",
              "4175   F   0.625     0.485  ...          0.2610        0.2960     10\n",
              "4176   M   0.710     0.555  ...          0.3765        0.4950     12\n",
              "\n",
              "[4177 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DT-dTAqwTGv6"
      },
      "source": [
        "Karena kita ingin memprediksi umur (Age), maka variabel Age nantinya akan menjadi variabel dependen atau target. Akan tetapi variabel age belum ada, maka harus dibuat terlebih dahulu. Berdasarkan dari deskripsi pada dataset, kolom Age bisa didapat dari penjumlahan 1.5 dengan data setiap row di kolom Rings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPJOt0tbRNtg"
      },
      "source": [
        "df[\"Age\"] = df[\"Rings\"] + 1.5"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfoFFXGhRQCF"
      },
      "source": [
        "# memisahkan features dan target\n",
        "y = df.Age\n",
        "X = df.drop(['Age'], axis=1)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeQO4WaiTjPV"
      },
      "source": [
        "# membagi dataset menjadi train set dan validation set (80 20)\n",
        "X_train_full, X_valid_full, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvVGw2M3Wz5Q"
      },
      "source": [
        "Variabel \"Sex\" merupakan categorical variable, jadi harus dipreprocessing terlebih dahulu. Ada 3 metode untuk melakukannya, yaitu Drop categorical variablenya, ordinal encoding, atau one-hot encoding. Untuk kasus ini, metode Drop & one-hot encoding memungkinkan ketimbang ordinal encoding, karena jika ingin melakukan ordinal encoding, variabel \"Sex\" tidak memiliki tingkatan (rank)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pM_OjvUdWdy_"
      },
      "source": [
        "# drop variabel \"sex\"\n",
        "drop_X_train = X_train_full.select_dtypes(exclude=['object'])\n",
        "drop_X_valid = X_valid_full.select_dtypes(exclude=['object'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab5C75PRW8_D",
        "outputId": "5b1b694d-db63-460a-ebbf-26d0cd94210c"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "reg = LinearRegression()\n",
        "reg.fit(drop_X_train, y_train)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kD-5IVQFdsu_",
        "outputId": "aaae461d-b69a-469b-bada-1ee6981df90f"
      },
      "source": [
        "# Mencari nilai R - squared untuk mengukur explanatory power dari features\n",
        "r2 = reg.score(drop_X_valid, y_valid)\n",
        "print(f\"R-squared : {r2}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R-squared : 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuqUN5YhjXXz"
      },
      "source": [
        "![adjusted r squared.jpeg](data:image/jpeg;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qcgGrPgqgEZ"
      },
      "source": [
        "def adjusted_r2(r2, n, p):\n",
        "  hasil = 1 - (((1-r2)*(n-1)) / (n-p-1))\n",
        "  print(f\"Adjusted R-squared : {hasil}\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVlSrPJqia3n",
        "outputId": "cab4a634-a20b-44c4-ca63-0f5184b3ea86"
      },
      "source": [
        "drop_X_valid.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(836, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwO_ek7hgy9F",
        "outputId": "f61b0abc-9580-4521-8f08-c8c0df561c0a"
      },
      "source": [
        "# adjusted r2\n",
        "n = drop_X_valid.shape[0]\n",
        "p = drop_X_valid.shape[1]\n",
        "adjusted_r2(r2, n, p)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Adjusted R-squared : 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCd71HIghM8O"
      },
      "source": [
        "Nilai R-squared (r2) & Adjusted R-Squared (ar2) berjumlah 1. Ini artinya tidak ada error saat memprediksi menggunakan model diatas. Hal tersebut menandakan ada sesuatu yang salah, dugaan sementara saya ada pada datasetnya yang tidak bersih. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kR7rcS3j0LH"
      },
      "source": [
        "# drop variabel \"Rings\"\n",
        "dropRings_Xtrain = drop_X_train.drop(\"Rings\", axis=1)\n",
        "dropRings_Xvalid = drop_X_valid.drop(\"Rings\", axis=1)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nr-C1Z-fokJC",
        "outputId": "1893447b-552b-4c11-bd5c-2ef7a4d7b297"
      },
      "source": [
        "reg.fit(dropRings_Xtrain, y_train)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhyoHa33pNJu",
        "outputId": "e72faf7e-6396-4c67-fd39-54e6e26169ab"
      },
      "source": [
        "# Mencari nilai R - squared untuk mengukur explanatory power dari features\n",
        "r2 = reg.score(dropRings_Xvalid, y_valid)\n",
        "print(f\"R-squared : {r2}\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R-squared : 0.5300888107050662\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLf1yK-6pZw2",
        "outputId": "2e7cc9e0-94a2-40c6-ebda-4cf86647a3e6"
      },
      "source": [
        "dropRings_Xvalid.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(836, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkPSzAN_r3Ad",
        "outputId": "5274afed-2598-4330-e4e4-61e232625263"
      },
      "source": [
        "# adjusted r2\n",
        "n = dropRings_Xvalid.shape[0]\n",
        "p = dropRings_Xvalid.shape[1]\n",
        "adjusted_r2(r2, n, p)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Adjusted R-squared : 0.5261161315685148\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xx0SQD0sk-N0"
      },
      "source": [
        "Setelah drop variabel \"Rings\", ternyata nilai r2 dan ar2 turun menjadi masing2  0.530 dan 0.526. Walaupun nilainya kecil dari nilai r2 yang ideal (0.70 - 0.90), tapi lebih baik ketimbang mendapat r2 = 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3ujf8H1wFLt"
      },
      "source": [
        "# One-hot encoding\n",
        "X_train_full = X_train_full.drop(\"Rings\", axis=1)\n",
        "X_valid_full = X_valid_full.drop(\"Rings\", axis=1)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kn0_5BIpsVIo"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "X_train_full[\"Sex\"] = X_train_full['Sex'].astype('category').cat.codes.astype(\"float\")\n",
        "X_valid_full[\"Sex\"] = X_valid_full['Sex'].astype('category').cat.codes.astype(\"float\")\n",
        "\n",
        "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train_full[[\"Sex\"]]))\n",
        "OH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid_full[[\"Sex\"]]))\n",
        "\n",
        "OH_cols_train.index = X_train_full.index\n",
        "OH_cols_valid.index = X_valid_full.index\n",
        "\n",
        "num_X_train = X_train_full.drop(\"Sex\", axis=1)\n",
        "num_X_valid = X_valid_full.drop(\"Sex\", axis=1)\n",
        "\n",
        "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
        "OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddjD6JDOz0CO",
        "outputId": "d37acd2a-b77c-4ea7-a9c9-cbb6b18649cd"
      },
      "source": [
        "reg.fit(OH_X_train, y_train)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bx19LIQg1H1P",
        "outputId": "68deeccc-fe18-4451-aecc-7bc738dd96d4"
      },
      "source": [
        "r2 = reg.score(OH_X_valid, y_valid)\n",
        "print(f\"R-squared : {r2}\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R-squared : 0.5383751781320009\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhQxuLTC143x",
        "outputId": "17c5ddd6-ead0-45d2-ffcd-aca88eff51bc"
      },
      "source": [
        "OH_X_valid.shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(836, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCGzYwXf2Zzx",
        "outputId": "d0499e68-6c33-45bc-f7b2-47aefb048e58"
      },
      "source": [
        "# adjusted r2\n",
        "n = OH_X_valid.shape[0]\n",
        "p = OH_X_valid.shape[1]\n",
        "adjusted_r2(r2, n, p)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Adjusted R-squared : 0.5327797257457221\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdNzARUMnBRF"
      },
      "source": [
        "Setelah menggunakan metode one-hot encoding, nilai r2 & ar2 naik. artinya untuk kasus ini metode one-hot encoding lebih baik daripada drop variabel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5S7bbBZt2epH"
      },
      "source": [
        "# 3 fungsi untuk menggunakan algoritma ML yang berbeda\n",
        "# (OLS, Random Forest, dan XGBoost)\n",
        "# Saya menggunakan metrik mean squared error\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "def ols_score(X_train, X_valid, y_train, y_valid):\n",
        "  model = LinearRegression()\n",
        "  model.fit(X_train, y_train)\n",
        "  preds = model.predict(X_valid)\n",
        "  mse = mean_squared_error(y_valid, preds)\n",
        "  print(f\"MSE (OLS) : {mse}\") \n",
        "\n",
        "def rf_score(X_train, X_valid, y_train, y_valid):\n",
        "  model = RandomForestRegressor(n_estimators=50, random_state=1)\n",
        "  model.fit(X_train, y_train)\n",
        "  preds = model.predict(X_valid)\n",
        "  mse = mean_squared_error(y_valid, preds)\n",
        "  print(f\"MSE (Random Forest) : {mse}\") \n",
        "\n",
        "def xgb_score(X_train, X_valid, y_train, y_valid):\n",
        "  model = XGBRegressor(n_estimators=10000, learning_rate=0.035, random_state=0)\n",
        "  model.fit(X_train, y_train, early_stopping_rounds=5, eval_set=[(X_valid, y_valid)])\n",
        "  preds = model.predict(X_valid)\n",
        "  mse = mean_squared_error(y_valid, preds)\n",
        "  print(f\"MSE (XGBoost) : {mse}\") "
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cm6gosgZ3PNr",
        "outputId": "7d3473e5-8a20-49d7-d293-703f4be98494"
      },
      "source": [
        "ols_score(OH_X_train, OH_X_valid, y_train, y_valid)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE (OLS) : 5.013389185855263\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1YGIggd4WZG",
        "outputId": "b5caf9a7-7572-4119-a15e-779db85f8bcc"
      },
      "source": [
        "rf_score(OH_X_train, OH_X_valid, y_train, y_valid)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE (Random Forest) : 4.804708612440192\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cs_xdEWC5lU_",
        "outputId": "11fe266a-9c71-4f9f-ef7d-feab035d6c56"
      },
      "source": [
        "xgb_score(OH_X_train, OH_X_valid, y_train, y_valid)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[06:09:08] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[0]\tvalidation_0-rmse:10.9518\n",
            "Will train until validation_0-rmse hasn't improved in 5 rounds.\n",
            "[1]\tvalidation_0-rmse:10.5923\n",
            "[2]\tvalidation_0-rmse:10.2459\n",
            "[3]\tvalidation_0-rmse:9.91139\n",
            "[4]\tvalidation_0-rmse:9.59009\n",
            "[5]\tvalidation_0-rmse:9.27791\n",
            "[6]\tvalidation_0-rmse:8.9809\n",
            "[7]\tvalidation_0-rmse:8.69389\n",
            "[8]\tvalidation_0-rmse:8.41874\n",
            "[9]\tvalidation_0-rmse:8.15313\n",
            "[10]\tvalidation_0-rmse:7.89635\n",
            "[11]\tvalidation_0-rmse:7.64945\n",
            "[12]\tvalidation_0-rmse:7.41046\n",
            "[13]\tvalidation_0-rmse:7.1818\n",
            "[14]\tvalidation_0-rmse:6.96086\n",
            "[15]\tvalidation_0-rmse:6.75044\n",
            "[16]\tvalidation_0-rmse:6.54421\n",
            "[17]\tvalidation_0-rmse:6.34997\n",
            "[18]\tvalidation_0-rmse:6.15947\n",
            "[19]\tvalidation_0-rmse:5.97791\n",
            "[20]\tvalidation_0-rmse:5.80193\n",
            "[21]\tvalidation_0-rmse:5.63664\n",
            "[22]\tvalidation_0-rmse:5.4758\n",
            "[23]\tvalidation_0-rmse:5.32277\n",
            "[24]\tvalidation_0-rmse:5.17423\n",
            "[25]\tvalidation_0-rmse:5.03461\n",
            "[26]\tvalidation_0-rmse:4.89836\n",
            "[27]\tvalidation_0-rmse:4.76904\n",
            "[28]\tvalidation_0-rmse:4.64363\n",
            "[29]\tvalidation_0-rmse:4.52443\n",
            "[30]\tvalidation_0-rmse:4.41009\n",
            "[31]\tvalidation_0-rmse:4.30239\n",
            "[32]\tvalidation_0-rmse:4.19698\n",
            "[33]\tvalidation_0-rmse:4.0969\n",
            "[34]\tvalidation_0-rmse:4.00256\n",
            "[35]\tvalidation_0-rmse:3.9112\n",
            "[36]\tvalidation_0-rmse:3.82295\n",
            "[37]\tvalidation_0-rmse:3.73945\n",
            "[38]\tvalidation_0-rmse:3.66005\n",
            "[39]\tvalidation_0-rmse:3.58385\n",
            "[40]\tvalidation_0-rmse:3.51205\n",
            "[41]\tvalidation_0-rmse:3.44361\n",
            "[42]\tvalidation_0-rmse:3.37803\n",
            "[43]\tvalidation_0-rmse:3.31581\n",
            "[44]\tvalidation_0-rmse:3.25884\n",
            "[45]\tvalidation_0-rmse:3.20317\n",
            "[46]\tvalidation_0-rmse:3.15001\n",
            "[47]\tvalidation_0-rmse:3.09926\n",
            "[48]\tvalidation_0-rmse:3.05081\n",
            "[49]\tvalidation_0-rmse:3.00484\n",
            "[50]\tvalidation_0-rmse:2.96139\n",
            "[51]\tvalidation_0-rmse:2.92043\n",
            "[52]\tvalidation_0-rmse:2.88335\n",
            "[53]\tvalidation_0-rmse:2.84556\n",
            "[54]\tvalidation_0-rmse:2.81123\n",
            "[55]\tvalidation_0-rmse:2.77794\n",
            "[56]\tvalidation_0-rmse:2.74733\n",
            "[57]\tvalidation_0-rmse:2.71917\n",
            "[58]\tvalidation_0-rmse:2.68982\n",
            "[59]\tvalidation_0-rmse:2.66436\n",
            "[60]\tvalidation_0-rmse:2.63901\n",
            "[61]\tvalidation_0-rmse:2.61484\n",
            "[62]\tvalidation_0-rmse:2.59319\n",
            "[63]\tvalidation_0-rmse:2.57085\n",
            "[64]\tvalidation_0-rmse:2.55233\n",
            "[65]\tvalidation_0-rmse:2.53339\n",
            "[66]\tvalidation_0-rmse:2.51604\n",
            "[67]\tvalidation_0-rmse:2.49972\n",
            "[68]\tvalidation_0-rmse:2.4837\n",
            "[69]\tvalidation_0-rmse:2.46729\n",
            "[70]\tvalidation_0-rmse:2.45381\n",
            "[71]\tvalidation_0-rmse:2.44009\n",
            "[72]\tvalidation_0-rmse:2.42768\n",
            "[73]\tvalidation_0-rmse:2.41597\n",
            "[74]\tvalidation_0-rmse:2.40437\n",
            "[75]\tvalidation_0-rmse:2.39409\n",
            "[76]\tvalidation_0-rmse:2.38306\n",
            "[77]\tvalidation_0-rmse:2.3734\n",
            "[78]\tvalidation_0-rmse:2.36462\n",
            "[79]\tvalidation_0-rmse:2.35699\n",
            "[80]\tvalidation_0-rmse:2.34793\n",
            "[81]\tvalidation_0-rmse:2.34028\n",
            "[82]\tvalidation_0-rmse:2.33329\n",
            "[83]\tvalidation_0-rmse:2.32679\n",
            "[84]\tvalidation_0-rmse:2.32063\n",
            "[85]\tvalidation_0-rmse:2.31426\n",
            "[86]\tvalidation_0-rmse:2.30836\n",
            "[87]\tvalidation_0-rmse:2.30334\n",
            "[88]\tvalidation_0-rmse:2.29863\n",
            "[89]\tvalidation_0-rmse:2.29454\n",
            "[90]\tvalidation_0-rmse:2.28889\n",
            "[91]\tvalidation_0-rmse:2.28406\n",
            "[92]\tvalidation_0-rmse:2.27951\n",
            "[93]\tvalidation_0-rmse:2.27542\n",
            "[94]\tvalidation_0-rmse:2.27198\n",
            "[95]\tvalidation_0-rmse:2.2682\n",
            "[96]\tvalidation_0-rmse:2.26429\n",
            "[97]\tvalidation_0-rmse:2.26097\n",
            "[98]\tvalidation_0-rmse:2.25745\n",
            "[99]\tvalidation_0-rmse:2.2549\n",
            "[100]\tvalidation_0-rmse:2.25287\n",
            "[101]\tvalidation_0-rmse:2.25064\n",
            "[102]\tvalidation_0-rmse:2.24712\n",
            "[103]\tvalidation_0-rmse:2.24515\n",
            "[104]\tvalidation_0-rmse:2.24367\n",
            "[105]\tvalidation_0-rmse:2.24229\n",
            "[106]\tvalidation_0-rmse:2.24083\n",
            "[107]\tvalidation_0-rmse:2.23924\n",
            "[108]\tvalidation_0-rmse:2.23781\n",
            "[109]\tvalidation_0-rmse:2.23483\n",
            "[110]\tvalidation_0-rmse:2.23356\n",
            "[111]\tvalidation_0-rmse:2.23267\n",
            "[112]\tvalidation_0-rmse:2.23083\n",
            "[113]\tvalidation_0-rmse:2.22983\n",
            "[114]\tvalidation_0-rmse:2.22897\n",
            "[115]\tvalidation_0-rmse:2.22813\n",
            "[116]\tvalidation_0-rmse:2.22698\n",
            "[117]\tvalidation_0-rmse:2.22661\n",
            "[118]\tvalidation_0-rmse:2.22477\n",
            "[119]\tvalidation_0-rmse:2.22426\n",
            "[120]\tvalidation_0-rmse:2.22375\n",
            "[121]\tvalidation_0-rmse:2.22249\n",
            "[122]\tvalidation_0-rmse:2.22108\n",
            "[123]\tvalidation_0-rmse:2.22073\n",
            "[124]\tvalidation_0-rmse:2.22006\n",
            "[125]\tvalidation_0-rmse:2.21905\n",
            "[126]\tvalidation_0-rmse:2.21875\n",
            "[127]\tvalidation_0-rmse:2.21815\n",
            "[128]\tvalidation_0-rmse:2.21787\n",
            "[129]\tvalidation_0-rmse:2.21713\n",
            "[130]\tvalidation_0-rmse:2.21599\n",
            "[131]\tvalidation_0-rmse:2.21596\n",
            "[132]\tvalidation_0-rmse:2.21516\n",
            "[133]\tvalidation_0-rmse:2.21421\n",
            "[134]\tvalidation_0-rmse:2.2139\n",
            "[135]\tvalidation_0-rmse:2.21364\n",
            "[136]\tvalidation_0-rmse:2.21166\n",
            "[137]\tvalidation_0-rmse:2.21069\n",
            "[138]\tvalidation_0-rmse:2.21057\n",
            "[139]\tvalidation_0-rmse:2.21028\n",
            "[140]\tvalidation_0-rmse:2.20978\n",
            "[141]\tvalidation_0-rmse:2.20949\n",
            "[142]\tvalidation_0-rmse:2.20939\n",
            "[143]\tvalidation_0-rmse:2.20906\n",
            "[144]\tvalidation_0-rmse:2.20821\n",
            "[145]\tvalidation_0-rmse:2.20758\n",
            "[146]\tvalidation_0-rmse:2.20771\n",
            "[147]\tvalidation_0-rmse:2.20765\n",
            "[148]\tvalidation_0-rmse:2.20695\n",
            "[149]\tvalidation_0-rmse:2.20684\n",
            "[150]\tvalidation_0-rmse:2.20478\n",
            "[151]\tvalidation_0-rmse:2.20389\n",
            "[152]\tvalidation_0-rmse:2.20356\n",
            "[153]\tvalidation_0-rmse:2.20407\n",
            "[154]\tvalidation_0-rmse:2.20331\n",
            "[155]\tvalidation_0-rmse:2.20287\n",
            "[156]\tvalidation_0-rmse:2.20247\n",
            "[157]\tvalidation_0-rmse:2.20226\n",
            "[158]\tvalidation_0-rmse:2.20229\n",
            "[159]\tvalidation_0-rmse:2.20262\n",
            "[160]\tvalidation_0-rmse:2.20096\n",
            "[161]\tvalidation_0-rmse:2.20066\n",
            "[162]\tvalidation_0-rmse:2.19927\n",
            "[163]\tvalidation_0-rmse:2.19882\n",
            "[164]\tvalidation_0-rmse:2.19789\n",
            "[165]\tvalidation_0-rmse:2.19769\n",
            "[166]\tvalidation_0-rmse:2.19787\n",
            "[167]\tvalidation_0-rmse:2.19719\n",
            "[168]\tvalidation_0-rmse:2.19768\n",
            "[169]\tvalidation_0-rmse:2.19803\n",
            "[170]\tvalidation_0-rmse:2.1966\n",
            "[171]\tvalidation_0-rmse:2.19531\n",
            "[172]\tvalidation_0-rmse:2.19499\n",
            "[173]\tvalidation_0-rmse:2.19522\n",
            "[174]\tvalidation_0-rmse:2.19529\n",
            "[175]\tvalidation_0-rmse:2.19477\n",
            "[176]\tvalidation_0-rmse:2.19527\n",
            "[177]\tvalidation_0-rmse:2.19526\n",
            "[178]\tvalidation_0-rmse:2.19512\n",
            "[179]\tvalidation_0-rmse:2.1944\n",
            "[180]\tvalidation_0-rmse:2.19297\n",
            "[181]\tvalidation_0-rmse:2.19277\n",
            "[182]\tvalidation_0-rmse:2.19297\n",
            "[183]\tvalidation_0-rmse:2.19173\n",
            "[184]\tvalidation_0-rmse:2.19172\n",
            "[185]\tvalidation_0-rmse:2.19125\n",
            "[186]\tvalidation_0-rmse:2.19144\n",
            "[187]\tvalidation_0-rmse:2.19123\n",
            "[188]\tvalidation_0-rmse:2.19091\n",
            "[189]\tvalidation_0-rmse:2.19099\n",
            "[190]\tvalidation_0-rmse:2.19072\n",
            "[191]\tvalidation_0-rmse:2.19036\n",
            "[192]\tvalidation_0-rmse:2.19041\n",
            "[193]\tvalidation_0-rmse:2.19087\n",
            "[194]\tvalidation_0-rmse:2.18979\n",
            "[195]\tvalidation_0-rmse:2.19004\n",
            "[196]\tvalidation_0-rmse:2.18971\n",
            "[197]\tvalidation_0-rmse:2.19008\n",
            "[198]\tvalidation_0-rmse:2.18967\n",
            "[199]\tvalidation_0-rmse:2.18974\n",
            "[200]\tvalidation_0-rmse:2.18951\n",
            "[201]\tvalidation_0-rmse:2.18925\n",
            "[202]\tvalidation_0-rmse:2.1881\n",
            "[203]\tvalidation_0-rmse:2.18784\n",
            "[204]\tvalidation_0-rmse:2.18774\n",
            "[205]\tvalidation_0-rmse:2.18784\n",
            "[206]\tvalidation_0-rmse:2.18812\n",
            "[207]\tvalidation_0-rmse:2.1879\n",
            "[208]\tvalidation_0-rmse:2.1879\n",
            "[209]\tvalidation_0-rmse:2.1881\n",
            "Stopping. Best iteration:\n",
            "[204]\tvalidation_0-rmse:2.18774\n",
            "\n",
            "MSE (XGBoost) : 4.786220126012435\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGB7R20a6Pkh",
        "outputId": "ff2c5f74-2caf-42e6-c3e8-d0ea356c3742"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "model = tf.keras.models.Sequential([    \n",
        "        # shape 10 karna kolom berjumlah 10 setelah OH encoding          \n",
        "        tf.keras.layers.Input(shape=(10,)), \n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(1)\n",
        "    ])\n",
        "\n",
        "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"mse\"])\n",
        "model.fit(OH_X_train, y_train, epochs=500)\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "105/105 [==============================] - 1s 3ms/step - loss: 47.6197 - mse: 47.6197\n",
            "Epoch 2/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 7.2005 - mse: 7.2005\n",
            "Epoch 3/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 6.6358 - mse: 6.6358\n",
            "Epoch 4/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 6.3347 - mse: 6.3347\n",
            "Epoch 5/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 6.0657 - mse: 6.0657\n",
            "Epoch 6/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 5.8495 - mse: 5.8495\n",
            "Epoch 7/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 5.7150 - mse: 5.7150\n",
            "Epoch 8/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 5.4736 - mse: 5.4736\n",
            "Epoch 9/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 5.2495 - mse: 5.2495\n",
            "Epoch 10/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 5.0649 - mse: 5.0649\n",
            "Epoch 11/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.9806 - mse: 4.9806\n",
            "Epoch 12/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.8917 - mse: 4.8917\n",
            "Epoch 13/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.7916 - mse: 4.7916\n",
            "Epoch 14/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.7616 - mse: 4.7616\n",
            "Epoch 15/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.6628 - mse: 4.6628\n",
            "Epoch 16/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.7394 - mse: 4.7394\n",
            "Epoch 17/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.6201 - mse: 4.6201\n",
            "Epoch 18/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.6138 - mse: 4.6138\n",
            "Epoch 19/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.6203 - mse: 4.6203\n",
            "Epoch 20/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.6056 - mse: 4.6056\n",
            "Epoch 21/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.7509 - mse: 4.7509\n",
            "Epoch 22/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.5842 - mse: 4.5842\n",
            "Epoch 23/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.5284 - mse: 4.5284\n",
            "Epoch 24/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.6118 - mse: 4.6118\n",
            "Epoch 25/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.7201 - mse: 4.7201\n",
            "Epoch 26/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.5802 - mse: 4.5802\n",
            "Epoch 27/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.6107 - mse: 4.6107\n",
            "Epoch 28/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.5355 - mse: 4.5355\n",
            "Epoch 29/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.5690 - mse: 4.5690\n",
            "Epoch 30/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.4930 - mse: 4.4930\n",
            "Epoch 31/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.5031 - mse: 4.5031\n",
            "Epoch 32/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.6198 - mse: 4.6198\n",
            "Epoch 33/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.4868 - mse: 4.4868\n",
            "Epoch 34/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.4765 - mse: 4.4765\n",
            "Epoch 35/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.4805 - mse: 4.4805\n",
            "Epoch 36/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.4860 - mse: 4.4860\n",
            "Epoch 37/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.4862 - mse: 4.4862\n",
            "Epoch 38/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.5034 - mse: 4.5034\n",
            "Epoch 39/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.4382 - mse: 4.4382\n",
            "Epoch 40/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.5096 - mse: 4.5096\n",
            "Epoch 41/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.5136 - mse: 4.5136\n",
            "Epoch 42/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.4863 - mse: 4.4863\n",
            "Epoch 43/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.4183 - mse: 4.4183\n",
            "Epoch 44/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.4329 - mse: 4.4329\n",
            "Epoch 45/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.5036 - mse: 4.5036\n",
            "Epoch 46/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.4828 - mse: 4.4828\n",
            "Epoch 47/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.4184 - mse: 4.4184\n",
            "Epoch 48/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.4104 - mse: 4.4104\n",
            "Epoch 49/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.4220 - mse: 4.4220\n",
            "Epoch 50/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.4189 - mse: 4.4189\n",
            "Epoch 51/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.4385 - mse: 4.4385\n",
            "Epoch 52/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.4140 - mse: 4.4140\n",
            "Epoch 53/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.3587 - mse: 4.3587\n",
            "Epoch 54/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.4422 - mse: 4.4422\n",
            "Epoch 55/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.3783 - mse: 4.3783\n",
            "Epoch 56/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.4204 - mse: 4.4204\n",
            "Epoch 57/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.3786 - mse: 4.3786\n",
            "Epoch 58/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.4083 - mse: 4.4083\n",
            "Epoch 59/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.3924 - mse: 4.3924\n",
            "Epoch 60/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.3499 - mse: 4.3499\n",
            "Epoch 61/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.4005 - mse: 4.4005\n",
            "Epoch 62/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.3813 - mse: 4.3813\n",
            "Epoch 63/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.3970 - mse: 4.3970\n",
            "Epoch 64/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.4278 - mse: 4.4278\n",
            "Epoch 65/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.4032 - mse: 4.4032\n",
            "Epoch 66/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.3727 - mse: 4.3727\n",
            "Epoch 67/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.3409 - mse: 4.3409\n",
            "Epoch 68/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.3747 - mse: 4.3747\n",
            "Epoch 69/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.3515 - mse: 4.3515\n",
            "Epoch 70/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.3663 - mse: 4.3663\n",
            "Epoch 71/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.3246 - mse: 4.3246\n",
            "Epoch 72/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.3811 - mse: 4.3811\n",
            "Epoch 73/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.3491 - mse: 4.3491\n",
            "Epoch 74/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.4018 - mse: 4.4018\n",
            "Epoch 75/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.4065 - mse: 4.4065\n",
            "Epoch 76/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.3396 - mse: 4.3396\n",
            "Epoch 77/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.3591 - mse: 4.3591\n",
            "Epoch 78/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.3387 - mse: 4.3387\n",
            "Epoch 79/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.4086 - mse: 4.4086\n",
            "Epoch 80/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.3570 - mse: 4.3570\n",
            "Epoch 81/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.4250 - mse: 4.4250\n",
            "Epoch 82/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.3288 - mse: 4.3288\n",
            "Epoch 83/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.3134 - mse: 4.3134\n",
            "Epoch 84/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.3327 - mse: 4.3327\n",
            "Epoch 85/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.3552 - mse: 4.3552\n",
            "Epoch 86/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2968 - mse: 4.2968\n",
            "Epoch 87/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.4151 - mse: 4.4151\n",
            "Epoch 88/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.3346 - mse: 4.3346\n",
            "Epoch 89/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2911 - mse: 4.2911\n",
            "Epoch 90/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.3898 - mse: 4.3898\n",
            "Epoch 91/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.3200 - mse: 4.3200\n",
            "Epoch 92/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.3683 - mse: 4.3683\n",
            "Epoch 93/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.3328 - mse: 4.3328\n",
            "Epoch 94/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2981 - mse: 4.2981\n",
            "Epoch 95/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2935 - mse: 4.2935\n",
            "Epoch 96/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.3323 - mse: 4.3323\n",
            "Epoch 97/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2986 - mse: 4.2986\n",
            "Epoch 98/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.3851 - mse: 4.3851\n",
            "Epoch 99/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2980 - mse: 4.2980\n",
            "Epoch 100/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2904 - mse: 4.2904\n",
            "Epoch 101/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.3247 - mse: 4.3247\n",
            "Epoch 102/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2738 - mse: 4.2738\n",
            "Epoch 103/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2988 - mse: 4.2988\n",
            "Epoch 104/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2904 - mse: 4.2904\n",
            "Epoch 105/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.3002 - mse: 4.3002\n",
            "Epoch 106/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.3077 - mse: 4.3077\n",
            "Epoch 107/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2459 - mse: 4.2459\n",
            "Epoch 108/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.3249 - mse: 4.3249\n",
            "Epoch 109/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.3286 - mse: 4.3286\n",
            "Epoch 110/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2774 - mse: 4.2774\n",
            "Epoch 111/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.3563 - mse: 4.3563\n",
            "Epoch 112/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2802 - mse: 4.2802\n",
            "Epoch 113/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.3567 - mse: 4.3567\n",
            "Epoch 114/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.3047 - mse: 4.3047\n",
            "Epoch 115/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2656 - mse: 4.2656\n",
            "Epoch 116/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.3206 - mse: 4.3206\n",
            "Epoch 117/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2801 - mse: 4.2801\n",
            "Epoch 118/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2783 - mse: 4.2783\n",
            "Epoch 119/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.2488 - mse: 4.2488\n",
            "Epoch 120/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2993 - mse: 4.2993\n",
            "Epoch 121/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2929 - mse: 4.2929\n",
            "Epoch 122/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2895 - mse: 4.2895\n",
            "Epoch 123/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2517 - mse: 4.2517\n",
            "Epoch 124/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2981 - mse: 4.2981\n",
            "Epoch 125/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2893 - mse: 4.2893\n",
            "Epoch 126/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2694 - mse: 4.2694\n",
            "Epoch 127/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2675 - mse: 4.2675\n",
            "Epoch 128/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2546 - mse: 4.2546\n",
            "Epoch 129/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.3314 - mse: 4.3314\n",
            "Epoch 130/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2947 - mse: 4.2947\n",
            "Epoch 131/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2825 - mse: 4.2825\n",
            "Epoch 132/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2399 - mse: 4.2399\n",
            "Epoch 133/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2570 - mse: 4.2570\n",
            "Epoch 134/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2955 - mse: 4.2955\n",
            "Epoch 135/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2824 - mse: 4.2824\n",
            "Epoch 136/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2506 - mse: 4.2506\n",
            "Epoch 137/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2381 - mse: 4.2381\n",
            "Epoch 138/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2480 - mse: 4.2480\n",
            "Epoch 139/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2558 - mse: 4.2558\n",
            "Epoch 140/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.3066 - mse: 4.3066\n",
            "Epoch 141/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.3609 - mse: 4.3609\n",
            "Epoch 142/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2337 - mse: 4.2337\n",
            "Epoch 143/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2797 - mse: 4.2797\n",
            "Epoch 144/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2745 - mse: 4.2745\n",
            "Epoch 145/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2744 - mse: 4.2744\n",
            "Epoch 146/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2305 - mse: 4.2305\n",
            "Epoch 147/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2699 - mse: 4.2699\n",
            "Epoch 148/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.3144 - mse: 4.3144\n",
            "Epoch 149/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2668 - mse: 4.2668\n",
            "Epoch 150/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2549 - mse: 4.2549\n",
            "Epoch 151/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2478 - mse: 4.2478\n",
            "Epoch 152/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2477 - mse: 4.2477\n",
            "Epoch 153/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2344 - mse: 4.2344\n",
            "Epoch 154/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2700 - mse: 4.2700\n",
            "Epoch 155/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2190 - mse: 4.2190\n",
            "Epoch 156/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2122 - mse: 4.2122\n",
            "Epoch 157/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2190 - mse: 4.2190\n",
            "Epoch 158/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2062 - mse: 4.2062\n",
            "Epoch 159/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2314 - mse: 4.2314\n",
            "Epoch 160/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.3148 - mse: 4.3148\n",
            "Epoch 161/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2085 - mse: 4.2085\n",
            "Epoch 162/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2107 - mse: 4.2107\n",
            "Epoch 163/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2599 - mse: 4.2599\n",
            "Epoch 164/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1839 - mse: 4.1839\n",
            "Epoch 165/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2038 - mse: 4.2038\n",
            "Epoch 166/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2432 - mse: 4.2432\n",
            "Epoch 167/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2311 - mse: 4.2311\n",
            "Epoch 168/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2749 - mse: 4.2749\n",
            "Epoch 169/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2260 - mse: 4.2260\n",
            "Epoch 170/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2646 - mse: 4.2646\n",
            "Epoch 171/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2061 - mse: 4.2061\n",
            "Epoch 172/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2264 - mse: 4.2264\n",
            "Epoch 173/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2054 - mse: 4.2054\n",
            "Epoch 174/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2209 - mse: 4.2209\n",
            "Epoch 175/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2288 - mse: 4.2288\n",
            "Epoch 176/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2313 - mse: 4.2313\n",
            "Epoch 177/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2701 - mse: 4.2701\n",
            "Epoch 178/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2240 - mse: 4.2240\n",
            "Epoch 179/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2291 - mse: 4.2291\n",
            "Epoch 180/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2402 - mse: 4.2402\n",
            "Epoch 181/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2160 - mse: 4.2160\n",
            "Epoch 182/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2601 - mse: 4.2601\n",
            "Epoch 183/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2989 - mse: 4.2989\n",
            "Epoch 184/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1876 - mse: 4.1876\n",
            "Epoch 185/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.4120 - mse: 4.4120\n",
            "Epoch 186/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2477 - mse: 4.2477\n",
            "Epoch 187/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2135 - mse: 4.2135\n",
            "Epoch 188/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2265 - mse: 4.2265\n",
            "Epoch 189/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2493 - mse: 4.2493\n",
            "Epoch 190/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1974 - mse: 4.1974\n",
            "Epoch 191/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2075 - mse: 4.2075\n",
            "Epoch 192/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2429 - mse: 4.2429\n",
            "Epoch 193/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2189 - mse: 4.2189\n",
            "Epoch 194/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2381 - mse: 4.2381\n",
            "Epoch 195/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1932 - mse: 4.1932\n",
            "Epoch 196/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2187 - mse: 4.2187\n",
            "Epoch 197/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2068 - mse: 4.2068\n",
            "Epoch 198/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2148 - mse: 4.2148\n",
            "Epoch 199/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2327 - mse: 4.2327\n",
            "Epoch 200/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2067 - mse: 4.2067\n",
            "Epoch 201/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2035 - mse: 4.2035\n",
            "Epoch 202/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1951 - mse: 4.1951\n",
            "Epoch 203/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2157 - mse: 4.2157\n",
            "Epoch 204/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2538 - mse: 4.2538\n",
            "Epoch 205/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2229 - mse: 4.2229\n",
            "Epoch 206/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2121 - mse: 4.2121\n",
            "Epoch 207/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2602 - mse: 4.2602\n",
            "Epoch 208/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1925 - mse: 4.1925\n",
            "Epoch 209/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2489 - mse: 4.2489\n",
            "Epoch 210/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2331 - mse: 4.2331\n",
            "Epoch 211/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2235 - mse: 4.2235\n",
            "Epoch 212/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2156 - mse: 4.2156\n",
            "Epoch 213/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2189 - mse: 4.2189\n",
            "Epoch 214/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2339 - mse: 4.2339\n",
            "Epoch 215/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2123 - mse: 4.2123\n",
            "Epoch 216/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1833 - mse: 4.1833\n",
            "Epoch 217/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2271 - mse: 4.2271\n",
            "Epoch 218/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2038 - mse: 4.2038\n",
            "Epoch 219/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1714 - mse: 4.1714\n",
            "Epoch 220/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2227 - mse: 4.2227\n",
            "Epoch 221/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2115 - mse: 4.2115\n",
            "Epoch 222/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.3549 - mse: 4.3549\n",
            "Epoch 223/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2097 - mse: 4.2097\n",
            "Epoch 224/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2266 - mse: 4.2266\n",
            "Epoch 225/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2374 - mse: 4.2374\n",
            "Epoch 226/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2215 - mse: 4.2215\n",
            "Epoch 227/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1924 - mse: 4.1924\n",
            "Epoch 228/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2646 - mse: 4.2646\n",
            "Epoch 229/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1958 - mse: 4.1958\n",
            "Epoch 230/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1839 - mse: 4.1839\n",
            "Epoch 231/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1816 - mse: 4.1816\n",
            "Epoch 232/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2776 - mse: 4.2776\n",
            "Epoch 233/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2808 - mse: 4.2808\n",
            "Epoch 234/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1496 - mse: 4.1496\n",
            "Epoch 235/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1902 - mse: 4.1902\n",
            "Epoch 236/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1584 - mse: 4.1584\n",
            "Epoch 237/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1740 - mse: 4.1740\n",
            "Epoch 238/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1731 - mse: 4.1731\n",
            "Epoch 239/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2067 - mse: 4.2067\n",
            "Epoch 240/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2171 - mse: 4.2171\n",
            "Epoch 241/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1720 - mse: 4.1720\n",
            "Epoch 242/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1609 - mse: 4.1609\n",
            "Epoch 243/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1880 - mse: 4.1880\n",
            "Epoch 244/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2638 - mse: 4.2638\n",
            "Epoch 245/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1653 - mse: 4.1653\n",
            "Epoch 246/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1926 - mse: 4.1926\n",
            "Epoch 247/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1780 - mse: 4.1780\n",
            "Epoch 248/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2244 - mse: 4.2244\n",
            "Epoch 249/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2083 - mse: 4.2083\n",
            "Epoch 250/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2267 - mse: 4.2267\n",
            "Epoch 251/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1661 - mse: 4.1661\n",
            "Epoch 252/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2566 - mse: 4.2566\n",
            "Epoch 253/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1750 - mse: 4.1750\n",
            "Epoch 254/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.2085 - mse: 4.2085\n",
            "Epoch 255/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1905 - mse: 4.1905\n",
            "Epoch 256/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1925 - mse: 4.1925\n",
            "Epoch 257/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1816 - mse: 4.1816\n",
            "Epoch 258/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1675 - mse: 4.1675\n",
            "Epoch 259/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1703 - mse: 4.1703\n",
            "Epoch 260/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1533 - mse: 4.1533\n",
            "Epoch 261/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2199 - mse: 4.2199\n",
            "Epoch 262/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1886 - mse: 4.1886\n",
            "Epoch 263/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1844 - mse: 4.1844\n",
            "Epoch 264/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1586 - mse: 4.1586\n",
            "Epoch 265/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1670 - mse: 4.1670\n",
            "Epoch 266/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1960 - mse: 4.1960\n",
            "Epoch 267/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1886 - mse: 4.1886\n",
            "Epoch 268/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1982 - mse: 4.1982\n",
            "Epoch 269/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2245 - mse: 4.2245\n",
            "Epoch 270/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1473 - mse: 4.1473\n",
            "Epoch 271/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2431 - mse: 4.2431\n",
            "Epoch 272/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1423 - mse: 4.1423\n",
            "Epoch 273/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2098 - mse: 4.2098\n",
            "Epoch 274/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1974 - mse: 4.1974\n",
            "Epoch 275/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2712 - mse: 4.2712\n",
            "Epoch 276/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1716 - mse: 4.1716\n",
            "Epoch 277/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1920 - mse: 4.1920\n",
            "Epoch 278/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1733 - mse: 4.1733\n",
            "Epoch 279/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1835 - mse: 4.1835\n",
            "Epoch 280/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1133 - mse: 4.1133\n",
            "Epoch 281/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1781 - mse: 4.1781\n",
            "Epoch 282/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1482 - mse: 4.1482\n",
            "Epoch 283/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1838 - mse: 4.1838\n",
            "Epoch 284/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2870 - mse: 4.2870\n",
            "Epoch 285/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1713 - mse: 4.1713\n",
            "Epoch 286/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1535 - mse: 4.1535\n",
            "Epoch 287/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1959 - mse: 4.1959\n",
            "Epoch 288/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1644 - mse: 4.1644\n",
            "Epoch 289/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1737 - mse: 4.1737\n",
            "Epoch 290/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1680 - mse: 4.1680\n",
            "Epoch 291/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2050 - mse: 4.2050\n",
            "Epoch 292/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2225 - mse: 4.2225\n",
            "Epoch 293/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1331 - mse: 4.1331\n",
            "Epoch 294/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1437 - mse: 4.1437\n",
            "Epoch 295/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1560 - mse: 4.1560\n",
            "Epoch 296/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1532 - mse: 4.1532\n",
            "Epoch 297/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2304 - mse: 4.2304\n",
            "Epoch 298/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2978 - mse: 4.2978\n",
            "Epoch 299/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1447 - mse: 4.1447\n",
            "Epoch 300/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1472 - mse: 4.1472\n",
            "Epoch 301/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1853 - mse: 4.1853\n",
            "Epoch 302/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1959 - mse: 4.1959\n",
            "Epoch 303/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1245 - mse: 4.1245\n",
            "Epoch 304/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1307 - mse: 4.1307\n",
            "Epoch 305/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1953 - mse: 4.1953\n",
            "Epoch 306/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1543 - mse: 4.1543\n",
            "Epoch 307/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1279 - mse: 4.1279\n",
            "Epoch 308/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1720 - mse: 4.1720\n",
            "Epoch 309/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1608 - mse: 4.1608\n",
            "Epoch 310/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1366 - mse: 4.1366\n",
            "Epoch 311/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1599 - mse: 4.1599\n",
            "Epoch 312/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1448 - mse: 4.1448\n",
            "Epoch 313/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1338 - mse: 4.1338\n",
            "Epoch 314/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1319 - mse: 4.1319\n",
            "Epoch 315/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2196 - mse: 4.2196\n",
            "Epoch 316/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1198 - mse: 4.1198\n",
            "Epoch 317/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1895 - mse: 4.1895\n",
            "Epoch 318/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2131 - mse: 4.2131\n",
            "Epoch 319/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1714 - mse: 4.1714\n",
            "Epoch 320/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1184 - mse: 4.1184\n",
            "Epoch 321/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1136 - mse: 4.1136\n",
            "Epoch 322/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1093 - mse: 4.1093\n",
            "Epoch 323/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1389 - mse: 4.1389\n",
            "Epoch 324/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1739 - mse: 4.1739\n",
            "Epoch 325/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.2176 - mse: 4.2176\n",
            "Epoch 326/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2175 - mse: 4.2175\n",
            "Epoch 327/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1992 - mse: 4.1992\n",
            "Epoch 328/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1256 - mse: 4.1256\n",
            "Epoch 329/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1339 - mse: 4.1339\n",
            "Epoch 330/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1668 - mse: 4.1668\n",
            "Epoch 331/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1760 - mse: 4.1760\n",
            "Epoch 332/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1439 - mse: 4.1439\n",
            "Epoch 333/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1308 - mse: 4.1308\n",
            "Epoch 334/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1448 - mse: 4.1448\n",
            "Epoch 335/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1393 - mse: 4.1393\n",
            "Epoch 336/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1527 - mse: 4.1527\n",
            "Epoch 337/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1097 - mse: 4.1097\n",
            "Epoch 338/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1711 - mse: 4.1711\n",
            "Epoch 339/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1524 - mse: 4.1524\n",
            "Epoch 340/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1490 - mse: 4.1490\n",
            "Epoch 341/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1110 - mse: 4.1110\n",
            "Epoch 342/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0972 - mse: 4.0972\n",
            "Epoch 343/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1508 - mse: 4.1508\n",
            "Epoch 344/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1558 - mse: 4.1558\n",
            "Epoch 345/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1489 - mse: 4.1489\n",
            "Epoch 346/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1543 - mse: 4.1543\n",
            "Epoch 347/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1446 - mse: 4.1446\n",
            "Epoch 348/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1327 - mse: 4.1327\n",
            "Epoch 349/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1438 - mse: 4.1438\n",
            "Epoch 350/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1539 - mse: 4.1539\n",
            "Epoch 351/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1035 - mse: 4.1035\n",
            "Epoch 352/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1105 - mse: 4.1105\n",
            "Epoch 353/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.0718 - mse: 4.0718\n",
            "Epoch 354/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1153 - mse: 4.1153\n",
            "Epoch 355/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1332 - mse: 4.1332\n",
            "Epoch 356/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1111 - mse: 4.1111\n",
            "Epoch 357/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1373 - mse: 4.1373\n",
            "Epoch 358/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.0886 - mse: 4.0886\n",
            "Epoch 359/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1012 - mse: 4.1012\n",
            "Epoch 360/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1466 - mse: 4.1466\n",
            "Epoch 361/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1018 - mse: 4.1018\n",
            "Epoch 362/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.2051 - mse: 4.2051\n",
            "Epoch 363/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1376 - mse: 4.1376\n",
            "Epoch 364/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1213 - mse: 4.1213\n",
            "Epoch 365/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1213 - mse: 4.1213\n",
            "Epoch 366/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1396 - mse: 4.1396\n",
            "Epoch 367/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1047 - mse: 4.1047\n",
            "Epoch 368/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1534 - mse: 4.1534\n",
            "Epoch 369/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1638 - mse: 4.1638\n",
            "Epoch 370/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1421 - mse: 4.1421\n",
            "Epoch 371/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1627 - mse: 4.1627\n",
            "Epoch 372/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1619 - mse: 4.1619\n",
            "Epoch 373/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1006 - mse: 4.1006\n",
            "Epoch 374/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1004 - mse: 4.1004\n",
            "Epoch 375/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1008 - mse: 4.1008\n",
            "Epoch 376/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.0996 - mse: 4.0996\n",
            "Epoch 377/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1369 - mse: 4.1369\n",
            "Epoch 378/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1115 - mse: 4.1115\n",
            "Epoch 379/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1086 - mse: 4.1086\n",
            "Epoch 380/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1235 - mse: 4.1235\n",
            "Epoch 381/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1964 - mse: 4.1964\n",
            "Epoch 382/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.0966 - mse: 4.0966\n",
            "Epoch 383/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1007 - mse: 4.1007\n",
            "Epoch 384/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1132 - mse: 4.1132\n",
            "Epoch 385/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1141 - mse: 4.1141\n",
            "Epoch 386/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.0944 - mse: 4.0944\n",
            "Epoch 387/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0732 - mse: 4.0732\n",
            "Epoch 388/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1422 - mse: 4.1422\n",
            "Epoch 389/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1547 - mse: 4.1547\n",
            "Epoch 390/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1356 - mse: 4.1356\n",
            "Epoch 391/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0948 - mse: 4.0948\n",
            "Epoch 392/500\n",
            "105/105 [==============================] - 1s 5ms/step - loss: 4.1055 - mse: 4.1055\n",
            "Epoch 393/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0899 - mse: 4.0899\n",
            "Epoch 394/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0946 - mse: 4.0946\n",
            "Epoch 395/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1531 - mse: 4.1531\n",
            "Epoch 396/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0892 - mse: 4.0892\n",
            "Epoch 397/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1177 - mse: 4.1177\n",
            "Epoch 398/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0844 - mse: 4.0844\n",
            "Epoch 399/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0742 - mse: 4.0742\n",
            "Epoch 400/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0990 - mse: 4.0990\n",
            "Epoch 401/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1079 - mse: 4.1079\n",
            "Epoch 402/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1119 - mse: 4.1119\n",
            "Epoch 403/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0840 - mse: 4.0840\n",
            "Epoch 404/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0622 - mse: 4.0622\n",
            "Epoch 405/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0855 - mse: 4.0855\n",
            "Epoch 406/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1467 - mse: 4.1467\n",
            "Epoch 407/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1340 - mse: 4.1340\n",
            "Epoch 408/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0964 - mse: 4.0964\n",
            "Epoch 409/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1500 - mse: 4.1500\n",
            "Epoch 410/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0397 - mse: 4.0397\n",
            "Epoch 411/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0662 - mse: 4.0662\n",
            "Epoch 412/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0852 - mse: 4.0852\n",
            "Epoch 413/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1466 - mse: 4.1466\n",
            "Epoch 414/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.0920 - mse: 4.0920\n",
            "Epoch 415/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1398 - mse: 4.1398\n",
            "Epoch 416/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0959 - mse: 4.0959\n",
            "Epoch 417/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0673 - mse: 4.0673\n",
            "Epoch 418/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0940 - mse: 4.0940\n",
            "Epoch 419/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0742 - mse: 4.0742\n",
            "Epoch 420/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0866 - mse: 4.0866\n",
            "Epoch 421/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1057 - mse: 4.1057\n",
            "Epoch 422/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0781 - mse: 4.0781\n",
            "Epoch 423/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0755 - mse: 4.0755\n",
            "Epoch 424/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0610 - mse: 4.0610\n",
            "Epoch 425/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1469 - mse: 4.1469\n",
            "Epoch 426/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1405 - mse: 4.1405\n",
            "Epoch 427/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0691 - mse: 4.0691\n",
            "Epoch 428/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0622 - mse: 4.0622\n",
            "Epoch 429/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1092 - mse: 4.1092\n",
            "Epoch 430/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0683 - mse: 4.0683\n",
            "Epoch 431/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0570 - mse: 4.0570\n",
            "Epoch 432/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0726 - mse: 4.0726\n",
            "Epoch 433/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0633 - mse: 4.0633\n",
            "Epoch 434/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0844 - mse: 4.0844\n",
            "Epoch 435/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1122 - mse: 4.1122\n",
            "Epoch 436/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0951 - mse: 4.0951\n",
            "Epoch 437/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1050 - mse: 4.1050\n",
            "Epoch 438/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1033 - mse: 4.1033\n",
            "Epoch 439/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1376 - mse: 4.1376\n",
            "Epoch 440/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1336 - mse: 4.1336\n",
            "Epoch 441/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1042 - mse: 4.1042\n",
            "Epoch 442/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0526 - mse: 4.0526\n",
            "Epoch 443/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0921 - mse: 4.0921\n",
            "Epoch 444/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0548 - mse: 4.0548\n",
            "Epoch 445/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0641 - mse: 4.0641\n",
            "Epoch 446/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0544 - mse: 4.0544\n",
            "Epoch 447/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1132 - mse: 4.1132\n",
            "Epoch 448/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0849 - mse: 4.0849\n",
            "Epoch 449/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1007 - mse: 4.1007\n",
            "Epoch 450/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1517 - mse: 4.1517\n",
            "Epoch 451/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0746 - mse: 4.0746\n",
            "Epoch 452/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0148 - mse: 4.0148\n",
            "Epoch 453/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0703 - mse: 4.0703\n",
            "Epoch 454/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0306 - mse: 4.0306\n",
            "Epoch 455/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1165 - mse: 4.1165\n",
            "Epoch 456/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1119 - mse: 4.1119\n",
            "Epoch 457/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.0840 - mse: 4.0840\n",
            "Epoch 458/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0545 - mse: 4.0545\n",
            "Epoch 459/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1283 - mse: 4.1283\n",
            "Epoch 460/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.0340 - mse: 4.0340\n",
            "Epoch 461/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1073 - mse: 4.1073\n",
            "Epoch 462/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.1109 - mse: 4.1109\n",
            "Epoch 463/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0864 - mse: 4.0864\n",
            "Epoch 464/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0581 - mse: 4.0581\n",
            "Epoch 465/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0440 - mse: 4.0440\n",
            "Epoch 466/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0721 - mse: 4.0721\n",
            "Epoch 467/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0529 - mse: 4.0529\n",
            "Epoch 468/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0421 - mse: 4.0421\n",
            "Epoch 469/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0444 - mse: 4.0444\n",
            "Epoch 470/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0581 - mse: 4.0581\n",
            "Epoch 471/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0940 - mse: 4.0940\n",
            "Epoch 472/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0327 - mse: 4.0327\n",
            "Epoch 473/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0857 - mse: 4.0857\n",
            "Epoch 474/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0430 - mse: 4.0430\n",
            "Epoch 475/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1300 - mse: 4.1300\n",
            "Epoch 476/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0343 - mse: 4.0343\n",
            "Epoch 477/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0477 - mse: 4.0477\n",
            "Epoch 478/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1463 - mse: 4.1463\n",
            "Epoch 479/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0535 - mse: 4.0535\n",
            "Epoch 480/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0470 - mse: 4.0470\n",
            "Epoch 481/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0686 - mse: 4.0686\n",
            "Epoch 482/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0620 - mse: 4.0620\n",
            "Epoch 483/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0662 - mse: 4.0662\n",
            "Epoch 484/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0142 - mse: 4.0142\n",
            "Epoch 485/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0395 - mse: 4.0395\n",
            "Epoch 486/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1473 - mse: 4.1473\n",
            "Epoch 487/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0374 - mse: 4.0374\n",
            "Epoch 488/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0432 - mse: 4.0432\n",
            "Epoch 489/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1628 - mse: 4.1628\n",
            "Epoch 490/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0576 - mse: 4.0576\n",
            "Epoch 491/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.1221 - mse: 4.1221\n",
            "Epoch 492/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0914 - mse: 4.0914\n",
            "Epoch 493/500\n",
            "105/105 [==============================] - 0s 3ms/step - loss: 4.0130 - mse: 4.0130\n",
            "Epoch 494/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0360 - mse: 4.0360\n",
            "Epoch 495/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0678 - mse: 4.0678\n",
            "Epoch 496/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0963 - mse: 4.0963\n",
            "Epoch 497/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0034 - mse: 4.0034\n",
            "Epoch 498/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0330 - mse: 4.0330\n",
            "Epoch 499/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0293 - mse: 4.0293\n",
            "Epoch 500/500\n",
            "105/105 [==============================] - 0s 4ms/step - loss: 4.0204 - mse: 4.0204\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fec18596790>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hW8Pri3i87Z9",
        "outputId": "eea670c7-844f-41ea-99af-8e423a0e4cd6"
      },
      "source": [
        "model.evaluate(OH_X_valid, y_valid, verbose=0)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4.419747352600098, 4.419747352600098]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnimWJQisI1_"
      },
      "source": [
        "Model terprediksi dengan sempurna berdasarkan hasil dari cell diatas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lnTbppHrea8"
      },
      "source": [
        "**Kesimpulan**\n",
        "\n",
        "*   MSE (OLS) : 5.013389185855263\n",
        "*   MSE (Random Forest) : 4.804708612440192\n",
        "*   MSE (XGBoost) : 4.786220126012435\n",
        "*   MSE (DNN) : 4.0204"
      ]
    }
  ]
}